{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-class Reading: Day 16 (Nov 01, 2023)<br>Fitting\n",
    "Learning goals\n",
    "1. Use `scipy.optimize.curve_fit` to fit an x-y data set to a model and extract the fitting parameters\n",
    "1. Use extracted fitting parameters to plot the best fit model\n",
    "1. Extract uncertainties from fitting parameters\n",
    "1. Include absoulte y-data uncertainties in the fit\n",
    "1. Make good initial guesses of the fitting parameters to improve the chance that the real best fit will be found instead of a local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *No self-assessment questions for this reading*\n",
    "\n",
    "Although you have likely interacted with many of these concepts in Physics 219 and elsewhere, we're presenting some of the details in different ways that you may have encountered so would like everybody to work their way through this notebook and then submit it as if it was a regular reading assignment with self-assessment quesitons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *16.1 Fitting with `scipy.optimize.curve_fit`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main fitting routine that we will use in this course is the `scipy` fitting routine `curve_fit()`. You can read more about it at:\n",
    "    \n",
    "* http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\n",
    "\n",
    "This fitting routine uses non-linear least squares fitting. For those of you that took Physics 119, this is the same as minimizing chi-squared by minimizing the sum of the residuals squared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *16.2 An initial linear fit without uncertainties*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we provide a data set that we expect should be modelled by a straight line, $y=mx+b$. Let's first plot these data so we have a sense of what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = np.array([.04, .06, .08, .1 , .13, .15])\n",
    "y_data = np.array([3.14, 3.89, 4.04, 4.33, 4.67, 5.08])\n",
    "yerror = np.array([0.52, 0.22, 0.53, 0.53, 0.24, 0.54])\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=yerror, fmt = \"bo\", capsize=5)\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on some quick mental math, we can get initial estimates of the slope and y-intercept for this data set. Let us initially ignore the uncertainties and notice that the data set has a rise of approximately 2 units ($\\approx 5-3$) over the entire data set and a run of approximately 0.1 units ($\\approx 0.14-0.04$). Thus the slope is approximately $2/0.1 \\approx 20$. A reasonable estimate for the y-intercept would be $\\approx 2.0 \\mbox{ units}$.\n",
    "\n",
    "Let's run the fit and double-check that the results make some sense. Note that we do have y-uncertainties in our data set (`yerror`), but we are not yet using them with `curve_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows us to use scipy's 'optimize.curve_fit'\n",
    "from scipy import optimize\n",
    "\n",
    "# Like with solve_ivp, we need to define a function that curve_fit will interact with\n",
    "# - The first parameter will always be the x variable\n",
    "# - The subsequent parameters will be our parameters for our fitting function\n",
    "# - Finally, we return what this function would calculate our y value to be\n",
    "#   so that curve_fit can compare it to y_data\n",
    "def line(x, m, b):\n",
    "    return m*x + b\n",
    "\n",
    "# curve_fit returns a tuple consisting of\n",
    "# - An array of our best-fit parameters, which we call fitparams\n",
    "# - A covariance matrix (fitcov) from which we can extract the uncertainties in our\n",
    "#   best-fit parameters.\n",
    "fitparams, fitcov = optimize.curve_fit(line, x_data, y_data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"m = {fitparams[0]:.1f};  b = {fitparams[1]:.2f}\")\n",
    "\n",
    "# The diagnonal of the covariance matrix gives the variance (standard deviation squared)\n",
    "# of our fitting parameters and the off-diagnonals communicate the correlations between\n",
    "# our fitting parameters. To get the uncertainty in each fitting parameter, we need to take\n",
    "# the square root of the variance.\n",
    "print(f\"dm = {np.sqrt(fitcov[0,0]):.2};  db = {np.sqrt(fitcov[1,1]):.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that our initial estimates were plausible, but more that one standard deviation away from the actual results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's graph the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's plot the best fit line\n",
    "\n",
    "# Produce enough x values over the data range to be able to make smooth curve\n",
    "xf = np.linspace(x_data.min(), x_data.max(), num = 50)\n",
    "\n",
    "# Re-use our `line` function from before and give it our best-fit parameters\n",
    "# - `*` in `*fitparams` unpacks it into fitparams[0] and fitparams[1] when\n",
    "#   it is being sent to the `line` function\n",
    "yf = line(xf, *fitparams)\n",
    "\n",
    "# Plot the best fit line\n",
    "plt.plot(xf, yf, \"r-\", label=\"Fit (ignoring uncertainties)\")\n",
    "\n",
    "## Let's bring back the previous graph\n",
    "plt.errorbar(x_data, y_data, yerr=yerror, fmt = \"bo\", capsize=5, label=\"Data\")\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the next step and include the y-uncertainties from our data in the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *16.3 Including uncertainties in our fit*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use two optional arguments to communicate to `curve_fit` that we want it to use the data y-uncertainties in our fit. This will use the standard approach to weighting each data point by 1/yerror<sup>2</sup>. \n",
    "1. Our first optional argument is `sigma=yerror`, which tells `curve_fit` that our \"one sigma\" errors are stored in `yerror`. \n",
    "2. Our second optional argument is `absolute_sigma=True`, which tells `curve_fit` to treat these as absolute errors, which is how we are plotting them. If set to `False` or not specified, `curve_fit` will treat these as relative errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can re-use our previous `line` function so just need to call `curve_fit` with\n",
    "# our new optional arguments\n",
    "\n",
    "fitparams2, fitcov2 = optimize.curve_fit(line, x_data, y_data, sigma=yerror, absolute_sigma=True)\n",
    "\n",
    "print(f\"m = {fitparams2[0]:.1f};  b = {fitparams2[1]:.2f}\")\n",
    "print(f\"dm = {np.sqrt(fitcov2[0,0]):.2};  db = {np.sqrt(fitcov2[1,1]):.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our results. Note that since we already have `xf` and `yf`, we just need to find the `yf2`, the y-values predicted by our `line` function when using `fitparams2` instead of `fitparams`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf2 = line(xf, *fitparams2)\n",
    "\n",
    "# Plot the best fit line\n",
    "plt.plot(xf, yf, \"r-\", label=\"Fit (ignoring uncertainties)\")\n",
    "plt.plot(xf, yf2, \"g--\", label=\"Fit (including uncertainties)\")\n",
    "\n",
    "## Let's bring back the previous graph\n",
    "plt.errorbar(x_data, y_data, yerr=yerror, fmt = \"bo\", capsize=5, label=\"Data\")\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the including `yerror` in the fit as absolute errors results in a fit that gives much more weight to the two data points with small uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *16.4 initial guesses*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of least-squares fitting involves looking for a minumum in the sum of the residuals (distance between the data and the value predicted by the model) squares. Models will tend to have an absolute minimum value for this, corresponding to the best possible fit of that model to those data, but many models will also have many local minima. This means that `curve_fit` may find a solution that minimizes the sum of the residuals squared as compared to nearby variations of the solution parameters, but which is not absolute minimum. Let's take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load some initial data and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "t_data = np.array([ 0.        ,  0.25645654,  0.51291309,  0.76936963,  1.02582617,\n",
    "        1.28228272,  1.53873926,  1.7951958 ,  2.05165235,  2.30810889,\n",
    "        2.56456543,  2.82102197,  3.07747852,  3.33393506,  3.5903916 ,\n",
    "        3.84684815,  4.10330469,  4.35976123,  4.61621778,  4.87267432,\n",
    "        5.12913086,  5.38558741,  5.64204395,  5.89850049,  6.15495704,\n",
    "        6.41141358,  6.66787012,  6.92432667,  7.18078321,  7.43723975,\n",
    "        7.69369629,  7.95015284,  8.20660938,  8.46306592,  8.71952247,\n",
    "        8.97597901,  9.23243555,  9.4888921 ,  9.74534864, 10.00180518,\n",
    "       10.25826173, 10.51471827, 10.77117481, 11.02763136, 11.2840879 ,\n",
    "       11.54054444, 11.79700098, 12.05345753, 12.30991407, 12.56637061])\n",
    "y_data = np.array([-1.71815239e-03, -2.08015913e-01,  5.64748219e-01,  9.62492904e-01,\n",
    "        9.20418866e-01,  9.35737259e-01,  1.32776675e+00,  1.58956031e+00,\n",
    "        1.88558979e+00,  1.66143882e+00,  2.03767118e+00,  2.25638778e+00,\n",
    "        2.00445035e+00,  2.04773244e+00,  2.17685040e+00,  1.88546903e+00,\n",
    "        1.81505858e+00,  1.48373884e+00,  1.59274906e+00,  1.57320479e+00,\n",
    "        9.91393316e-01,  1.08707412e+00,  7.51733967e-01, -4.56799784e-02,\n",
    "       -3.91397237e-01, -1.96417994e-01, -2.74839190e-01, -4.23692135e-01,\n",
    "       -7.91822825e-01, -1.31857939e+00, -1.12749963e+00, -1.84915218e+00,\n",
    "       -1.90104185e+00, -2.06498665e+00, -1.90021998e+00, -1.85630497e+00,\n",
    "       -2.16964289e+00, -2.38494504e+00, -1.79373814e+00, -1.84252623e+00,\n",
    "       -1.61829111e+00, -1.70084067e+00, -1.63726353e+00, -1.41318373e+00,\n",
    "       -1.14480241e+00, -1.20080281e+00, -9.50884586e-01, -8.69321294e-01,\n",
    "       -1.45618763e-01, -2.32657944e-01])\n",
    "\n",
    "plt.scatter(t_data, y_data, s=10, label='Data')\n",
    "plt.xlabel('t values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're expecting these data to obey a model $a \\sin{\\omega t}$.\n",
    "\n",
    "Like we did previously, we can get some initial estimates of the parameters just by knowing the model function and inspecting the behaviour of the data. Since this is a sin wave, we can quite easily see that we expect $a \\approx 2$. Additionally, we can also see that it takes approximately 12 time units to go through one full period and the relationship between period and angular frequency is $\\omega = 2\\pi/T$, giving us $\\omega \\approx 2\\pi/12 \\approx 0.5$. Let's keep these values in mind as we proceed with this fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first do a fit in the same way we have done it so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sum of sine waves function\n",
    "def sin_model(x, a, omega):\n",
    "    return a * np.sin(omega * x)\n",
    "\n",
    "# Fit with no initial guess\n",
    "popt_no_guess, pcov_no_guess = curve_fit(sin_model, t_data, y_data)\n",
    "\n",
    "# Print the \"no guess\" best fit parameters\n",
    "print(f\"a = {popt_no_guess[0]:.3};  omega = {popt_no_guess[1]:.3}\")\n",
    "\n",
    "# Generate our graphs\n",
    "plt.scatter(t_data, y_data, s=10, label='Data')\n",
    "plt.plot(t_data, sin_model(t_data, *popt_no_guess), 'r-', label='Fit (no initial guess)')\n",
    "plt.xlabel('t values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why did this fail so spectacularly???**\n",
    "\n",
    "The final aspect of using `curve_fit` that we have not yet discussed is that all fitting functions need to start with initial \"guesses\" of the fitting parameters and then `curve_fit` varies these parameters slowly while monitoring the sum of residuals squared to determine when it has found a minimum. Importantly, if we don't give it an initial guess, it uses values of `1` for each parameter.\n",
    "\n",
    "Let's include what the model `sin_model` looks like with initial guesses of $a=1$ and $\\omega=1$, labelled \"sin_model with initial guesses = 1\" in the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(t_data, y_data, s=10, label='Data')\n",
    "plt.plot(t_data, sin_model(t_data, 1, 1), 'b-', label='sin_model with initial guesses = 1')\n",
    "plt.plot(t_data, sin_model(t_data, *popt_no_guess), 'r-', label='Best fit with initial guesses = 1')\n",
    "plt.xlabel('t values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial guess of the angular frequency of 1 was approximately twice as large as what we estimated from the graph. As a result `curve_fit` struggled to get out of its local minimum by adjusting omega and ultimately ended up reducing the amplitude dramatically to reduce the very large penalty being applied due to the largest residuals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we provide our estimates from the start of this section ($a\\approx 2$ and $\\omega \\approx 0.5$) as an optional argument to `curve_fit` using `p0=[2, 0.5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with an initial guess\n",
    "popt_guess, pcov_guess = curve_fit(sin_model, t_data, y_data, p0=[2, 0.5])\n",
    "\n",
    "# Plot\n",
    "plt.scatter(t_data, y_data, s=10, label='Data')\n",
    "plt.plot(t_data, sin_model(t_data, *popt_no_guess), 'r-', label='Fit (no initial guess)')\n",
    "plt.plot(t_data, sin_model(t_data, *popt_guess), 'g-', label='Fit (with initial guess)')\n",
    "plt.xlabel('t values')\n",
    "plt.ylabel('y values')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you can see the importance of initial guesses when fitting to nonlinear functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Submitting this reading assignment*\n",
    "Before submitting your work, please ensure you have worked carefully through all the cells. Afterward choose: File >> Save_and_Export_Notebook_As >> HTML. This will download an HTML version of your notebook to your computer which you can upload to Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
